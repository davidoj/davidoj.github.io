# Counterfactuals and closest worlds


A recap of [chapter 1](/causality/01_three_questions): 

Three key questions about causes and effects are:
 1. What does it mean to say something causes something else?
 2. How do we learn that something causes something else?
 3. What is the purpose of learning that something causes something else?

We established that if one thing causes another then we should observe that these two things are associated, and that observing associations is part of the process of learning causal relationships. We also established that there is *something else* to causal relationships beyond association (which Hume called a "necessary connection"), but we didn't say much about what it was. Finally, we discussed some possible reasons why we learn causal relationships over an above just learning association rules.

Contemporary work on causality is carried out by philosophers and practitioners (statisticians, econometricians, epidemiologists and so on). While it isn't a hard rule, philosophical work is more concerned with explaining what it means to say something causes something else, and practical work is more concerned with the question of how we can learn that something causes something else. Along with formal accounts of what causes are or when you can learn them, theories of causation often also provide tools to reason more explicitly using our informal understanding of causality. I think the counterfactual theory of causation, which I discuss here, should really be understood to have two versions, one which is attempting to be a formal account of causation and another which attempts to help us leverage our informal understanding of causality.

The counterfactual theory of causality is that A) causal relationships express counterfactual dependence and B) we can determine counterfactual dependence by examining *possible worlds*. There is a lot to be said to adequately explain both A) and B), and I’m going to try to get away with saying just a little.

The key idea behind counterfactual dependence is that there are multiple ways an event "could" play out, given different initial conditions. Imagine you are in the middle of cooking spaghetti bolognese and have a sliced chili in your hand, ready to add to the pot. From here, imagine two different paths the future could take:
    1. You tip your hand and add the chili to the pot
    2. You pause for a second, and then decide to set the chili aside
Clearly, in world 1 you would expect that your bolognese would be hot, while in world 2 your bolognese would not be hot. By comparing the "chili world", where the bolognese is hot, with the "no chili world", where it is not, we can conclude that the bolognese being hot *counterfactually depends* on whether or not we put chili into the pot. This comparison of “possible worlds” is the basic feature of counterfactual analysis. Having established counterfactual dependence (B), we can then say (A) because the bolognese being hot counterfactually depends on the addition of chili, the addition of chili caused the bolognese to be hot (...with some caveats, if you dig deeply into the question).

What I have described is the counterfactual *way of thinking*, a way to leverage informal knowledge I have about bolognese and chili to establish a causal relationship. The counterfactual way of thinking can also be useful for discovering causal relationships that I'm not yet sure of. For example, if I want to find out “does the measles vaccine protect against measles?”, I can imagine two worlds - one in which everyone going to the doctor for a vaccine receives it as usual, and another where all the same people go to see their doctor, but all the vaccines were surreptitiously switched for an inert placebo. On the basis of the counterfactual theory I can then say that if the same individuals in both worlds contract measles, I can conclude that the vaccines did not offer protection. On the other hand, if some individuals contract measles in the placebo world but the same individuals do not contract it in the vaccination world, I could conclude that the vaccination protected those individuals from measles. Now, I clearly can't actually conjure up these two simultaneous parallel worlds, but maybe I can still learn some things about what would have happened in each if in the real world I surreptitiously switch some vaccines for placebos but not others.

While this is a useful way of thinking about causal relationships, when we pursue this idea a little more we run into a similar problem to our original problem with saying what causation is. We have established that we have *really strong* intuitions about some things causing other things, and it is easy to explain the same causal claim using different synonyms, but it is hard to explain a causal claim using only more basic ideas. The tough question for the counterfactual way of thinking is *what actually happens in all these parallel worlds?* Just like with causal relationships, I have an overwhelming intuition that the world where I put chili in the pot will have hot bolognese in it and the world where I didn't will have not-hot bolognese. But why? I can easily say "because chili makes bolognese hot", but then I'm just back to giving synonyms for causation.

David Lewis has proposed that we can escape falling back on our intuitions about causality by [considering how *similar* these worlds are](https://plato.stanford.edu/entries/causation-counterfactual/), subject to the constraint that in one world there is chili in the pot and in the other there is not. He defines a multi-faceted notion of similarity, which considers issues of "how the worlds are arranged" (for example, worlds 1 and 2 will be more similar if the sauce is boiling in both than if it is boiling in one and frozen in the other) as well as "how physics operates" (for example, worlds 1 and 2 will be more similar if chili tastes hot in both than if it tastes hot in one world but not in the other). Equipped with such a notion of similarity, we can then answer the question of "what happens in world 2?" by noting that it is whatever happens in the world most similar to world 1, except with no chili in the bolognese pot.

If it is possible to come up with a measure of the similarity of worlds along these lines that reproduces all of our strong causal intuitions, I think this would be a very serious candidate for explaining how we learn causal relationships - namely, by employing some approximation of this similarity measure in combination with our ongoing experience of the real world. As far as I understand, however, there aren't any strong candidates for such a measure in existence at this point (you can check the [previous link](https://plato.stanford.edu/entries/causation-counterfactual/) for a couple of proposals). Even if the actual measure has not yet been found, it could still be the case that similarity of some kind is the concept underlying causal inference. My guess is that, even if this is true, we are still quite far from actually finding such a similarity measure.

To my knowledge, a formal or semi-formal version of closest-world counterfactuals has never been employed in any practical work on causal inference. On the other hand, the intuitive idea of different worlds playing out with similar but not quite identical starting conditions underpins the very popular [*Potential Outcomes*](http://www.stat.unipg.it/~stanghel/rubinjasa2005.pdf) approach to causal reasoning.

In the two examples I gave - putting chili in bolognese and switching vaccines for placebos - notice that the difference between the two worlds involves someone *taking an action* in both cases. The counterfactual theory of causality as I've introduced it does not require for the difference between the two worlds to have been established by someone making a decision, but someone taking an action ended up in both the stories anyway. An alternative theory of causality makes this *taking of actions* the fundamental ingredient of causal relationships, and this is what I will introduce in [chapter 3](/causality/03_interventions).

## Addendum

In this text I discussed a definition of causation in terms of counterfactual dependence and raise the example of a medical trial to illustrate how we might learn about causes. Because it would be a distraction from the main message, I don't give the full definition of causation via counterfactuals, nor do I explain what one can actually deduce from a medical trial. If you want to know these things, refer to [this](https://plato.stanford.edu/entries/causation-counterfactual/) for counterfactual definitions of causation and [this](http://www.stat.unipg.it/~stanghel/rubinjasa2005.pdf) for an explanation of what you can conclude from an experimental trial.